{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import platform\n",
    "import json\n",
    "from ctypes import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"nouveau_dataset\"\n",
    "ACTION_SUBFOLDER = os.path.join(DATASET_FOLDER, \"A\")\n",
    "COMEDY_SUBFOLDER = os.path.join(DATASET_FOLDER, \"C\")\n",
    "HORROR_SUBFOLDER = os.path.join(DATASET_FOLDER, \"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NameImg(t):\n",
    "    title=t\n",
    "    for i in '<>:â€œ/\\\\|?*.':\n",
    "        if i in title:\n",
    "            title = title.replace(i, '')\n",
    "\n",
    "    title = title.replace(' ', '_')\n",
    "    return title\n",
    "\n",
    "def sort_movies(n,length):\n",
    "    res =[]\n",
    "    if(n<=0):\n",
    "        return res\n",
    "    if(n>length):\n",
    "        n=length\n",
    "    \n",
    "    while(True):\n",
    "        s = random.randrange(n)\n",
    "        if s not in res:\n",
    "            res.append(s)\n",
    "        if len(res)==n:\n",
    "            return res\n",
    "        \n",
    "def get_train_dataset(dataset,n):\n",
    "    train_dataset = []\n",
    "    index = sort_movies(n,len(dataset))\n",
    "    for i in index:\n",
    "        train_dataset.append(dataset[i])\n",
    "    return train_dataset,index\n",
    "\n",
    "def get_test_dataset(index, dataset):\n",
    "    test_dataset=[]\n",
    "    for i in range(0,len(dataset)):\n",
    "        if i not in index:\n",
    "            test_dataset.append(dataset[i])\n",
    "    return test_dataset\n",
    "\n",
    "def fill_x_and_y(folder_output, folder_input, dataset):\n",
    "    with open(folder_output) as f:\n",
    "        for line in f:\n",
    "            if line[0]!='[' and line[0]!=']':\n",
    "                lineJson=json.loads(line[:-2])\n",
    "                title = NameImg(lineJson[\"title\"])\n",
    "                file_path = os.path.join(folder_input, f\"{title}.png\")\n",
    "                if os.path.isfile(file_path):\n",
    "                    image = Image.open(file_path)\n",
    "                    image = image.resize((32,32))\n",
    "                    im_arr = np.array(image).flatten()\n",
    "                    new_row = {'image':np.array(im_arr)/255.0,'genre':lineJson['genre']}\n",
    "                    dataset.append(new_row)\n",
    "def import_dataset(file_path,folder):\n",
    "    dataset = []\n",
    "    fill_x_and_y(file_path, folder, dataset)\n",
    "    #fill_x_and_y('nouveau_dataset/Comedy.txt', COMEDY_SUBFOLDER, dataset)\n",
    "    #fill_x_and_y('nouveau_dataset/Horreur.txt', HORROR_SUBFOLDER, dataset)\n",
    "    return dataset\n",
    "\n",
    "def toList(arr):\n",
    "    return [j for i in arr for j in i]\n",
    "\n",
    "def accuracy(predicted_outputs, y_test):\n",
    "    sum_rslt = 0\n",
    "    for i in range(0,len(y_test)):\n",
    "        if predicted_outputs[i] == y_test[i]:\n",
    "            sum_rslt += 1\n",
    "    return sum_rslt / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_action = import_dataset('nouveau_dataset/Action.txt', ACTION_SUBFOLDER)\n",
    "dataset_comedy = import_dataset('nouveau_dataset/Comedy.txt', COMEDY_SUBFOLDER)\n",
    "dataset_horror = import_dataset('nouveau_dataset/Horreur.txt', HORROR_SUBFOLDER)\n",
    "\n",
    "train_dataset_action, index_action = get_train_dataset(dataset_action,293)\n",
    "test_dataset_action = get_test_dataset(index_action, dataset_action)\n",
    "\n",
    "train_dataset_comedy, index_comedy = get_train_dataset(dataset_comedy,380)\n",
    "test_dataset_comedy = get_test_dataset(index_comedy, dataset_comedy)\n",
    "\n",
    "train_dataset_horror, index_horror = get_train_dataset(dataset_horror,439)\n",
    "test_dataset_horror = get_test_dataset(index_horror, dataset_horror)\n",
    "\n",
    "train_dataset = train_dataset_action + train_dataset_comedy + train_dataset_horror\n",
    "test_dataset = test_dataset_action + test_dataset_comedy + test_dataset_horror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_shared_library = \"target/release/librust_lib.dylib\"\n",
    "path_to_shared_library_windows = \"target\\\\debug\\\\rust_lib.dll\"\n",
    "\n",
    "if(platform.system()=='Windows'):\n",
    "    my_lib = cdll.LoadLibrary(path_to_shared_library_windows)\n",
    "else : \n",
    "    my_lib = cdll.LoadLibrary(path_to_shared_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for image in train_dataset:\n",
    "    x_train.append(image['image'].tolist())\n",
    "    y_train.append(image['genre'])\n",
    "for image in test_dataset:\n",
    "    x_test.append(image['image'].tolist())\n",
    "    y_test.append(image['genre'])\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs_len= len(x_train[0])\n",
    "x_train = toList(x_train)\n",
    "y_train = toList(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So the accuracy is 0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "d = [3072,3]\n",
    "arr_size = len(d)\n",
    "arr_type = c_int * arr_size\n",
    "native_arr = arr_type(*d)\n",
    "\n",
    "#create model\n",
    "my_lib.create_mlp_model.argtypes = [arr_type, c_int]\n",
    "my_lib.create_mlp_model.restype = c_void_p\n",
    "model = my_lib.create_mlp_model(native_arr,arr_size)\n",
    "\n",
    "#train model\n",
    "x_len = len(x_train)\n",
    "y_len = len(y_train)\n",
    "\n",
    "inputs_type = c_float * x_len\n",
    "outputs_type = c_float * y_len\n",
    "\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model.argtypes = [c_void_p, inputs_type, outputs_type, c_float, c_int, c_int, c_int]\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model.restype = None\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model(model, inputs_type(*x_train), outputs_type(*y_train), 0.001, 100000, x_len, y_len)\n",
    "\n",
    "#predict for the test dataset\n",
    "sample_inputs_type = c_float * sample_inputs_len\n",
    "my_lib.predict_mlp_model_classification.argtypes = [c_void_p, sample_inputs_type, c_int]\n",
    "my_lib.predict_mlp_model_classification.restype = POINTER(c_float)\n",
    "predicted_outputs = []\n",
    "for p in x_test:\n",
    "    prediction = my_lib.predict_mlp_model_classification(model, sample_inputs_type(*p), sample_inputs_len)\n",
    "    prediction = np.ctypeslib.as_array(prediction,(3,))\n",
    "    predicted_outputs.append(prediction.tolist())\n",
    "\n",
    "accuracy_model = accuracy(predicted_outputs, y_test)\n",
    "print(f\"So the accuracy is {accuracy_model}\")\n",
    "#print(f\"So the predicted outputs are {predicted_outputs}\")\n",
    "#print(f\"And the actual outputs are {y_test} and the len is {len(y_test)}\")\n",
    "\n",
    "#save model\n",
    "my_lib.save_mlp_model.argtypes = [c_void_p, c_char_p]\n",
    "my_lib.save_mlp_model.restype = None\n",
    "my_lib.save_mlp_model(model,\"dataset_mlp.json\".encode(\"utf-8\"))\n",
    "#destroy\n",
    "my_lib.destroy_model.argtypes = [c_void_p]\n",
    "my_lib.destroy_model.restype = None\n",
    "my_lib.destroy_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_x_and_y(folder, x_list, y_list, label):\n",
    "    for file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try: \n",
    "            image = Image.open(file_path)\n",
    "            image = image.resize((8,8))\n",
    "            im_arr = np.array(image).flatten()\n",
    "            x_list.append(im_arr)\n",
    "            y_list.append(label)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "def import_dataset():\n",
    "    action = []\n",
    "    comedy = []\n",
    "    horror = []\n",
    "   \n",
    "    fill_x_and_y(TRAIN_ACTION_FOLDER, X_train, Y_train, 1.0)\n",
    "    fill_x_and_y(TRAIN_COMEDY_FOLDER, X_train, Y_train, -1.0)\n",
    "    fill_x_and_y(TEST_ACTION_FOLDER, X_test, Y_test, 1.0)\n",
    "    fill_x_and_y(TEST_COMEDY_FOLDER, X_test, Y_test, -1.0)\n",
    "    \n",
    "    return (np.array(X_train) / 255.0, np.array(Y_train)), (np.array(X_test)/255.0, np.array(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_shared_library = \"target/debug/librust_lib.dylib\"\n",
    "path_to_shared_library_windows = \"target\\\\debug\\\\rust_lib.dll\"\n",
    "\n",
    "if(platform.system()=='Windows'):\n",
    "    my_lib = cdll.LoadLibrary(path_to_shared_library_windows)\n",
    "else : \n",
    "    my_lib = cdll.LoadLibrary(path_to_shared_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lib.create_model.argtypes = [c_int]\n",
    "my_lib.create_model.restype = POINTER(c_float)\n",
    "\n",
    "arr_size = 2\n",
    "model = my_lib.create_model(arr_size)\n",
    "\n",
    "arr_size += 1\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X_train:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "flattened_inputs_len = len(flattened_dataset_inputs)\n",
    "flattened_outputs_len = len(Y_train)\n",
    "\n",
    "inputs_type = c_float * flattened_inputs_len\n",
    "outputs_type = c_float * flattened_outputs_len\n",
    "\n",
    "arr_type = type(model)\n",
    "\n",
    "my_lib.train_rosenblatt_linear_model.argtypes = [arr_type, inputs_type, outputs_type, c_int, c_float, c_int, c_int,c_int]\n",
    "my_lib.train_rosenblatt_linear_model.restype = None\n",
    "\n",
    "inputs_native = inputs_type(*flattened_dataset_inputs)\n",
    "outputs_native = outputs_type(*Y_train)\n",
    "my_lib.train_rosenblatt_linear_model(model, inputs_native, outputs_native, 10000, 0.001, arr_size, flattened_inputs_len,flattened_outputs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in X_test:\n",
    "    p_type = c_float * len(p)\n",
    "    break\n",
    "my_lib.predict_linear_model_classification.argtypes = [arr_type, p_type, c_int,c_int]\n",
    "my_lib.predict_linear_model_classification.restype = c_float\n",
    "\n",
    "predicted_outputs = [my_lib.predict_linear_model_classification(model, p_type(*p),arr_size,len(p)) for p in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lib.destroy_array.argtypes = [POINTER(c_float), c_int]\n",
    "my_lib.destroy_array.restype = None\n",
    "my_lib.destroy_array(model, arr_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [3072, 2, 3]\n",
    "arr_size = len(d)\n",
    "arr_type = c_int * arr_size\n",
    "native_arr = arr_type(*d)\n",
    "my_lib.create_mlp_model.argtypes = [arr_type, c_int]\n",
    "my_lib.create_mlp_model.restype = c_void_p\n",
    "\n",
    "model = my_lib.create_mlp_model(native_arr,arr_size)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X_train:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "flattened_inputs_len = len(flattened_dataset_inputs)\n",
    "flattened_outputs_len = len(Y_train)\n",
    "\n",
    "inputs_type = c_float * flattened_inputs_len\n",
    "outputs_type = c_float * flattened_outputs_len\n",
    "\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model.argtypes = [c_void_p,inputs_type,outputs_type,c_float,c_int,c_int,c_int]\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model.restype = None\n",
    "inputs_native = inputs_type(*flattened_dataset_inputs)\n",
    "outputs_native = outputs_type(*Y_train)\n",
    "\n",
    "my_lib.train_classification_stochastic_backdrop_mlp_model(model,inputs_native,outputs_native,0.001,100000,flattened_inputs_len,flattened_outputs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in X_test:\n",
    "    p_type = c_float * len(p)\n",
    "    break\n",
    "my_lib.predict_mlp_model_classification.argtypes = [c_void_p, p_type,c_int]\n",
    "my_lib.predict_mlp_model_classification.restype = POINTER(c_float)\n",
    "\n",
    "predicted_outputs = [my_lib.predict_mlp_model_classification(model, p_type(*p),len(p))[0] for p in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lib.destroy_model.argtypes = [c_void_p]\n",
    "my_lib.destroy_model.restype = None\n",
    "my_lib.destroy_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
